{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWMW6Y3fDQPh"
      },
      "source": [
        "# MNIST Handwritten Digit Classification\n",
        "\n",
        "## Overview\n",
        "This notebook implements a Convolutional Neural Network (CNN) for classifying handwritten digits from the MNIST dataset. The MNIST dataset contains 60,000 training images and 10,000 test images of handwritten digits (0-9), each 28x28 pixels in grayscale.\n",
        "\n",
        "## Project Goals\n",
        "- Build a lightweight CNN model with fewer than 25,000 parameters\n",
        "- Achieve high accuracy (>95%) on the MNIST test set\n",
        "- Implement proper data augmentation and regularization techniques\n",
        "- Visualize training progress and model performance\n",
        "\n",
        "## Key Features\n",
        "- **4-Block CNN Architecture**: Efficient convolutional blocks with transition layers\n",
        "- **Data Augmentation**: Random rotations, affine transforms, and color jittering\n",
        "- **Regularization**: Dropout layers and batch normalization techniques\n",
        "- **Global Average Pooling**: Reduces parameters compared to fully connected layers\n",
        "\n",
        "## Model Architecture Overview\n",
        "The model uses a 4-block CNN design:\n",
        "1. **Block 1**: Feature extraction (1‚Üí8‚Üí16‚Üí32 channels)\n",
        "2. **Block 2**: Pattern recognition (32‚Üí16‚Üí32‚Üí8 channels)\n",
        "3. **Block 3**: Higher-level features (8‚Üí16‚Üí16 channels)\n",
        "4. **Block 4**: Final feature refinement (16‚Üí32 channels)\n",
        "5. **GAP + FC**: Global average pooling + final classification layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KKZXp0FDoeJ"
      },
      "source": [
        "## 1. Import Required Libraries\n",
        "\n",
        "We'll import all the necessary libraries for building and training our CNN model:\n",
        "- **PyTorch**: Core deep learning framework\n",
        "- **torchvision**: For datasets and image transforms\n",
        "- **matplotlib**: For visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dPLHDfvR710P"
      },
      "outputs": [],
      "source": [
        "# Import core PyTorch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Import vision libraries for datasets and transforms\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Import additional libraries for visualization and utilities\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1. Reproducibility Setup\n",
        "\n",
        "For consistent and reproducible results across different runs and devices, we'll set seeds for all random number generators used in the pipeline:\n",
        "\n",
        "- **Python Random**: Built-in random module\n",
        "- **NumPy**: Scientific computing random numbers  \n",
        "- **PyTorch CPU**: PyTorch's CPU random number generator\n",
        "- **PyTorch CUDA**: NVIDIA GPU random number generator\n",
        "- **PyTorch MPS**: Apple Silicon GPU random number generator\n",
        "\n",
        "This ensures that data augmentation, model initialization, and training will produce identical results each time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé≤ Setting random seed to 42 for reproducibility\n",
            "  ‚úÖ MPS (Apple Silicon) seed set\n",
            "  ‚úÖ All random number generators seeded\n",
            "  üìã Note: Results should now be reproducible across runs\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"\n",
        "    Set seeds for all random number generators to ensure reproducible results.\n",
        "    \n",
        "    Args:\n",
        "        seed (int): Random seed value (default: 42)\n",
        "    \"\"\"\n",
        "    print(f\"üé≤ Setting random seed to {seed} for reproducibility\")\n",
        "    \n",
        "    # Set Python's built-in random seed\n",
        "    random.seed(seed)\n",
        "    \n",
        "    # Set NumPy random seed\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Set PyTorch random seed for CPU\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    # Set PyTorch random seed for CUDA (if available)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
        "        # Ensure deterministic operations on GPU\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        print(\"  ‚úÖ CUDA seeds set with deterministic operations enabled\")\n",
        "    \n",
        "    # Set PyTorch random seed for MPS (if available)\n",
        "    if torch.backends.mps.is_available():\n",
        "        torch.mps.manual_seed(seed)\n",
        "        print(\"  ‚úÖ MPS (Apple Silicon) seed set\")\n",
        "    \n",
        "    # Set environment variable for Python hash seed (for complete reproducibility)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    \n",
        "    print(\"  ‚úÖ All random number generators seeded\")\n",
        "    print(\"  üìã Note: Results should now be reproducible across runs\")\n",
        "\n",
        "# Set the global seed\n",
        "SEED = 42\n",
        "set_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cR1-0DfEIAa"
      },
      "source": [
        "## 2. Device Setup and GPU Detection\n",
        "\n",
        "We'll check for available compute devices in order of preference:\n",
        "1. **CUDA** (NVIDIA GPUs) - Best performance for deep learning\n",
        "2. **MPS** (Apple Silicon Metal) - Optimized for Mac M1/M2/M3 chips\n",
        "3. **CPU** - Fallback option for compatibility\n",
        "\n",
        "This ensures optimal performance across different hardware configurations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvaMA6XHEM5O",
        "outputId": "83555802-c1c7-4666-c579-696732a36e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Using Apple Silicon GPU (Metal Performance Shaders)\n",
            "Device selected: mps\n"
          ]
        }
      ],
      "source": [
        "# Check for available compute devices\n",
        "def get_device():\n",
        "    \"\"\"\n",
        "    Determine the best available device for computation.\n",
        "    Priority: CUDA > MPS (Mac GPU) > CPU\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"‚úÖ Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "        return device\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "        print(\"‚úÖ Using Apple Silicon GPU (Metal Performance Shaders)\")\n",
        "        return device\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"‚ö†Ô∏è  Using CPU (consider using GPU for faster training)\")\n",
        "        return device\n",
        "\n",
        "# Set the device for training\n",
        "device = get_device()\n",
        "print(f\"Device selected: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIna1kDSEWJX"
      },
      "source": [
        "## 3. Data Preprocessing and Augmentation\n",
        "\n",
        "### Training Transforms\n",
        "We apply several augmentation techniques to increase dataset diversity and improve model generalization:\n",
        "- **RandomRotation(5¬∞)**: Slight rotations to handle natural writing variations\n",
        "- **RandomAffine**: Translation, scaling, and shearing transforms\n",
        "- **ColorJitter**: Brightness and contrast variations\n",
        "- **Normalization**: Using MNIST statistics (mean=0.1307, std=0.3081)\n",
        "\n",
        "### Test Transforms  \n",
        "For testing, we only apply normalization to ensure consistent preprocessing while maintaining reproducible results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4XjL7RB-8Cch"
      },
      "outputs": [],
      "source": [
        "# Define data transformations for training (with augmentation)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.9, 1.1), shear=10),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Define data transformations for testing (no augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mqx3pKlEjfv"
      },
      "source": [
        "## 4. Dataset Loading and Data Loaders\n",
        "\n",
        "We'll download and prepare the MNIST dataset with appropriate batch sizes for efficient training:\n",
        "- **Batch size**: 32 (balances memory usage and gradient stability)\n",
        "- **Shuffle**: Training data shuffled for better convergence\n",
        "- **Workers**: Multiple workers for parallel data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-WzGcRY8E32",
        "outputId": "c279d761-9286-4abc-ecf2-7a427e56d205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 60,000\n",
            "Test samples: 10,000\n",
            "Number of classes: 10\n",
            "Image shape: torch.Size([1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST datasets with transforms\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "# Create data loaders for batch processing\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset):,}\")\n",
        "print(f\"Test samples: {len(test_dataset):,}\")\n",
        "print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
        "print(f\"Image shape: {train_dataset[0][0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DhyLvxRE_xA"
      },
      "source": [
        "## 5. Data Visualization and Exploration\n",
        "\n",
        "Let's examine our training data to understand what we're working with:\n",
        "- **Sample Images**: Visualize a batch of training images\n",
        "- **Data Shape**: Confirm tensor dimensions (batch_size, channels, height, width)  \n",
        "- **Label Distribution**: Understand class balance in the dataset\n",
        "- **Augmentation Effects**: See how data transforms affect the images\n",
        "\n",
        "This visualization helps ensure our data loading pipeline is working correctly and gives us insight into the dataset characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "eCCKcWIp8Pww",
        "outputId": "bd1905c7-9a87-45f9-e8b0-864fc5d408f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Size torch.Size([32, 1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 12 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_data, batch_label = next(iter(train_loader))\n",
        "print(f'Batch Size {batch_data.size()}')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(12):\n",
        "  plt.subplot(3,4,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(batch_data[i].squeeze(0), cmap='gray')\n",
        "  plt.title(batch_label[i].item())\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAiCL3yrFU-L"
      },
      "source": [
        "## 6. CNN Model Architecture\n",
        "\n",
        "Our **SmallMNISTNet4Block** is designed to be efficient yet powerful, staying under 25,000 parameters while achieving high accuracy.\n",
        "\n",
        "### Architecture Design Philosophy:\n",
        "- **Progressive Channel Reduction**: Each block processes features at different abstraction levels\n",
        "- **Transition Layers**: 1√ó1 convolutions reduce parameters and control information flow\n",
        "- **Strategic Dropout**: Applied at key points to prevent overfitting\n",
        "- **Global Average Pooling**: Replaces fully connected layers to reduce parameters\n",
        "- **Efficient Parameter Usage**: Every layer contributes meaningfully to the final result\n",
        "\n",
        "### Model Flow:\n",
        "```\n",
        "Input (1√ó28√ó28)\n",
        "‚Üì Block 1: Feature extraction (1‚Üí8‚Üí16‚Üí32‚Üí16 channels) + MaxPool + Dropout\n",
        "‚Üì Block 2: Pattern recognition (16‚Üí32‚Üí8 channels) + MaxPool + Dropout  \n",
        "‚Üì Block 3: High-level features (8‚Üí16 channels) + MaxPool + Dropout\n",
        "‚Üì Block 4: Final refinement (16‚Üí32 channels)\n",
        "‚Üì Global Average Pooling (32√ó1√ó1)\n",
        "‚Üì Linear Classification (32‚Üí10)\n",
        "‚Üì Output (10 classes)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PEwdHbHvZSwm"
      },
      "outputs": [],
      "source": [
        "class SmallMNISTNet4Block(nn.Module):\n",
        "    def __init__(self, dropout_prob=0.1):\n",
        "        super(SmallMNISTNet4Block, self).__init__()\n",
        "\n",
        "        # =============== BLOCK 1: Feature Extraction ===============\n",
        "        # Input: 1√ó28√ó28, RF=1\n",
        "        self.conv1_1 = nn.Conv2d(1, 8, 3, padding=1)    # ‚Üí 8√ó28√ó28\n",
        "        self.conv1_2 = nn.Conv2d(8, 16, 3, padding=1)   # ‚Üí 16√ó28√ó28\n",
        "        self.conv1_3 = nn.Conv2d(16, 32, 3, padding=1)  # ‚Üí 32√ó28√ó28\n",
        "        self.trans1 = nn.Conv2d(32, 16, 1)              # ‚Üí 16√ó28√ó28\n",
        "        # MaxPool2d(2): ‚Üí 16√ó14√ó14, RF=8\n",
        "        self.dropout1 = nn.Dropout2d(dropout_prob)       # ‚Üí 16√ó14√ó14\n",
        "\n",
        "        # =============== BLOCK 2: Pattern Recognition ===============\n",
        "        # Input: 16√ó14√ó14, RF=8\n",
        "        self.conv2_1 = nn.Conv2d(16, 16, 3, padding=1)  # ‚Üí 16√ó14√ó14\n",
        "        self.conv2_2 = nn.Conv2d(16, 32, 3, padding=1)  # ‚Üí 32√ó14√ó14\n",
        "        self.trans2 = nn.Conv2d(32, 8, 1)               # ‚Üí 8√ó14√ó14\n",
        "        # MaxPool2d(2): ‚Üí 8√ó7√ó7, RF=18\n",
        "        self.dropout2 = nn.Dropout2d(dropout_prob)       # ‚Üí 8√ó7√ó7\n",
        "\n",
        "        # =============== BLOCK 3: High-Level Features ===============\n",
        "        # Input: 8√ó7√ó7, RF=18\n",
        "        self.conv3_1 = nn.Conv2d(8, 16, 3, padding=1)   # ‚Üí 16√ó7√ó7\n",
        "        self.conv3_2 = nn.Conv2d(16, 16, 3, padding=1)  # ‚Üí 16√ó7√ó7\n",
        "        # MaxPool2d(2): ‚Üí 16√ó3√ó3, RF=38\n",
        "        self.dropout3 = nn.Dropout2d(dropout_prob)       # ‚Üí 16√ó3√ó3\n",
        "\n",
        "        # =============== BLOCK 4: Final Refinement ===============\n",
        "        # Input: 16√ó3√ó3, RF=38\n",
        "        self.conv4_1 = nn.Conv2d(16, 16, 3, padding=1)  # ‚Üí 16√ó3√ó3\n",
        "        self.conv4_2 = nn.Conv2d(16, 32, 3, padding=1)  # ‚Üí 32√ó3√ó3\n",
        "\n",
        "        # =============== GLOBAL POOLING & CLASSIFICATION ===============\n",
        "        # Input: 32√ó3√ó3, RF=70\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)               # ‚Üí 32√ó1√ó1\n",
        "        \n",
        "        # Input: 32 features, RF=70\n",
        "        self.fc = nn.Linear(32, 10)                      # ‚Üí 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # INPUT: x.shape = [batch, 1, 28, 28] | RF = 1\n",
        "        \n",
        "        # =============== BLOCK 1: Feature Extraction ===============\n",
        "        x = F.relu(self.conv1_1(x))      # [batch, 8, 28, 28]  \n",
        "        x = F.relu(self.conv1_2(x))      # [batch, 16, 28, 28] \n",
        "        x = F.relu(self.conv1_3(x))      # [batch, 32, 28, 28] \n",
        "        x = F.relu(self.trans1(x))       # [batch, 16, 28, 28] \n",
        "        x = F.max_pool2d(x, 2)           # [batch, 16, 14, 14] \n",
        "        x = self.dropout1(x)             # [batch, 16, 14, 14] \n",
        "\n",
        "        # =============== BLOCK 2: Pattern Recognition ===============  \n",
        "        x = F.relu(self.conv2_1(x))      # [batch, 16, 14, 14] \n",
        "        x = F.relu(self.conv2_2(x))      # [batch, 32, 14, 14] \n",
        "        x = F.relu(self.trans2(x))       # [batch, 8, 14, 14]  \n",
        "        x = F.max_pool2d(x, 2)           # [batch, 8, 7, 7]    \n",
        "        x = self.dropout2(x)             # [batch, 8, 7, 7]    \n",
        "\n",
        "        # =============== BLOCK 3: High-Level Features ===============\n",
        "        x = F.relu(self.conv3_1(x))      # [batch, 16, 7, 7]   \n",
        "        x = F.relu(self.conv3_2(x))      # [batch, 16, 7, 7]   \n",
        "        x = F.max_pool2d(x, 2)           # [batch, 16, 3, 3]   \n",
        "        x = self.dropout3(x)             # [batch, 16, 3, 3]   \n",
        "\n",
        "        # =============== BLOCK 4: Final Refinement ===============\n",
        "        x = F.relu(self.conv4_1(x))      # [batch, 16, 3, 3]   \n",
        "        x = F.relu(self.conv4_2(x))      # [batch, 32, 3, 3]   \n",
        "\n",
        "        # =============== GLOBAL POOLING & CLASSIFICATION ===============\n",
        "        x = self.gap(x)                  # [batch, 32, 1, 1]   \n",
        "        x = x.view(x.size(0), -1)        # [batch, 32]         \n",
        "        x = self.fc(x)                   # [batch, 10]         \n",
        "        \n",
        "        return F.log_softmax(x, dim=1)   # [batch, 10] (log probabilities)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz985g-NFm1c"
      },
      "source": [
        "## 7. Model Summary and Parameter Analysis\n",
        "\n",
        "Let's analyze our model architecture and verify it meets our parameter constraints:\n",
        "- **Total Parameters**: Should be < 25,000\n",
        "- **Memory Usage**: Efficient forward/backward pass\n",
        "- **Layer Distribution**: Balanced parameter allocation across blocks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJkyEL-PMOjE",
        "outputId": "da3a1ba9-0321-40b1-b2d1-ead957003d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "            Conv2d-2           [-1, 16, 28, 28]           1,168\n",
            "            Conv2d-3           [-1, 32, 28, 28]           4,640\n",
            "            Conv2d-4           [-1, 16, 28, 28]             528\n",
            "         Dropout2d-5           [-1, 16, 14, 14]               0\n",
            "            Conv2d-6           [-1, 16, 14, 14]           2,320\n",
            "            Conv2d-7           [-1, 32, 14, 14]           4,640\n",
            "            Conv2d-8            [-1, 8, 14, 14]             264\n",
            "         Dropout2d-9              [-1, 8, 7, 7]               0\n",
            "           Conv2d-10             [-1, 16, 7, 7]           1,168\n",
            "           Conv2d-11             [-1, 16, 7, 7]           2,320\n",
            "        Dropout2d-12             [-1, 16, 3, 3]               0\n",
            "           Conv2d-13             [-1, 16, 3, 3]           2,320\n",
            "           Conv2d-14             [-1, 32, 3, 3]           4,640\n",
            "AdaptiveAvgPool2d-15             [-1, 32, 1, 1]               0\n",
            "           Linear-16                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 24,418\n",
            "Trainable params: 24,418\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.56\n",
            "Params size (MB): 0.09\n",
            "Estimated Total Size (MB): 0.65\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = SmallMNISTNet4Block().to('cpu')\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Enhanced Training and Evaluation Functions\n",
        "\n",
        "We implement robust training and evaluation functions with comprehensive tracking and progress monitoring capabilities.\n",
        "\n",
        "### üöÄ Training Function Features (`train_epoch`)\n",
        "\n",
        "Our enhanced training function provides:\n",
        "\n",
        "- **Progress Visualization**: Real-time progress bars using `tqdm` showing current loss and accuracy\n",
        "- **Comprehensive Metrics**: Tracks both loss and accuracy throughout training\n",
        "- **Device Optimization**: Efficient GPU/MPS memory usage with `non_blocking=True`\n",
        "- **Memory Management**: Proper gradient zeroing and tensor operations\n",
        "- **Real-time Feedback**: Live updates of training metrics during each batch\n",
        "\n",
        "**Key Operations:**\n",
        "1. **Forward Pass**: Input ‚Üí Model ‚Üí Loss calculation\n",
        "2. **Backward Pass**: Gradient computation via backpropagation  \n",
        "3. **Optimization**: Parameter updates using Adam optimizer\n",
        "4. **Metrics Tracking**: Running totals for loss and accuracy\n",
        "5. **Progress Display**: Dynamic progress bar with live metrics\n",
        "\n",
        "### üìä Evaluation Function Features (`evaluate_model`)\n",
        "\n",
        "Our evaluation function ensures accurate model assessment:\n",
        "\n",
        "- **Evaluation Mode**: Sets model to `eval()` to disable dropout/batch norm training behavior\n",
        "- **No Gradient Computation**: Uses `torch.no_grad()` for memory efficiency\n",
        "- **Comprehensive Testing**: Processes entire test dataset with progress tracking\n",
        "- **Flexible Naming**: Supports different dataset names (Test/Validation)\n",
        "- **Consistent Metrics**: Same accuracy/loss calculations as training\n",
        "\n",
        "**Key Benefits:**\n",
        "- **Memory Efficient**: No gradient computation saves GPU memory\n",
        "- **Accurate Assessment**: Proper evaluation mode ensures realistic performance metrics\n",
        "- **Progress Tracking**: Visual feedback during evaluation process\n",
        "- **Consistent Interface**: Returns same format as training function\n",
        "\n",
        "### üîÑ Function Integration\n",
        "\n",
        "Both functions work together seamlessly:\n",
        "```python\n",
        "# Training phase\n",
        "train_loss, train_acc = train_epoch(model, device, train_loader, optimizer, criterion, epoch)\n",
        "\n",
        "# Evaluation phase  \n",
        "test_loss, test_acc = evaluate_model(model, device, test_loader, criterion, \"Test\")\n",
        "```\n",
        "\n",
        "This design enables:\n",
        "- **Easy Integration**: Drop-in replacements for basic train/test functions\n",
        "- **Comprehensive Logging**: Detailed metrics for analysis and debugging\n",
        "- **Professional Output**: Clean, informative progress displays\n",
        "- **Performance Monitoring**: Real-time feedback on training progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "J_ICqobTLtQU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_epoch(model, device, train_loader, optimizer, criterion, epoch=None):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch with comprehensive tracking and progress monitoring.\n",
        "    \n",
        "    Args:\n",
        "        model: The neural network model\n",
        "        device: Computing device (cuda/mps/cpu)\n",
        "        train_loader: DataLoader for training data\n",
        "        optimizer: Optimizer for parameter updates\n",
        "        criterion: Loss function\n",
        "        epoch: Current epoch number for display\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy_percentage)\n",
        "    \"\"\"\n",
        "    model.train()  # Set model to training mode\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    \n",
        "    # Create progress bar for training batches\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch} Training' if epoch else 'Training', \n",
        "                       leave=False, dynamic_ncols=True)\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
        "        # Move data to the appropriate device\n",
        "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
        "        \n",
        "        # Zero gradients from previous iteration\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update metrics\n",
        "        batch_loss = loss.item()\n",
        "        total_loss += batch_loss * data.size(0)\n",
        "        \n",
        "        # Calculate predictions and correct count\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct_predictions += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total_samples += data.size(0)\n",
        "        \n",
        "        # Update progress bar with current metrics\n",
        "        current_accuracy = 100. * correct_predictions / total_samples\n",
        "        progress_bar.set_postfix({\n",
        "            'Loss': f'{batch_loss:.4f}',\n",
        "            'Acc': f'{current_accuracy:.2f}%'\n",
        "        })\n",
        "    \n",
        "    # Calculate final epoch metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = 100. * correct_predictions / total_samples\n",
        "    \n",
        "    print(f'  Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.2f}%')\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def evaluate_model(model, device, test_loader, criterion, dataset_name=\"Test\"):\n",
        "    \"\"\"\n",
        "    Evaluate the model on test/validation data with comprehensive metrics.\n",
        "    \n",
        "    Args:\n",
        "        model: The neural network model\n",
        "        device: Computing device (cuda/mps/cpu)\n",
        "        test_loader: DataLoader for test data\n",
        "        criterion: Loss function\n",
        "        dataset_name: Name for display purposes (\"Test\" or \"Validation\")\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy_percentage)\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    \n",
        "    # Create progress bar for evaluation batches\n",
        "    progress_bar = tqdm(test_loader, desc=f'{dataset_name} Evaluation', \n",
        "                       leave=False, dynamic_ncols=True)\n",
        "    \n",
        "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
        "        for data, target in progress_bar:\n",
        "            # Move data to the appropriate device\n",
        "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
        "            \n",
        "            # Forward pass\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            # Update metrics\n",
        "            total_loss += loss.item() * data.size(0)\n",
        "            \n",
        "            # Calculate predictions and correct count\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct_predictions += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total_samples += data.size(0)\n",
        "            \n",
        "            # Update progress bar\n",
        "            current_accuracy = 100. * correct_predictions / total_samples\n",
        "            progress_bar.set_postfix({'Acc': f'{current_accuracy:.2f}%'})\n",
        "    \n",
        "    # Calculate final metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = 100. * correct_predictions / total_samples\n",
        "    \n",
        "    print(f'  {dataset_name} Loss: {avg_loss:.4f}, {dataset_name} Accuracy: {accuracy:.2f}%')\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6NPG4kw1Vg6-"
      },
      "outputs": [],
      "source": [
        "model = SmallMNISTNet4Block().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.5454, Train Accuracy: 81.66%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                               "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Test Loss: 0.0755, Test Accuracy: 97.56%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.07553554662927053, 97.56)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_epoch(model, device, train_loader, optimizer, criterion)\n",
        "evaluate_model(model, device, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "### üèÜ **Summary**\n",
        "\n",
        "**üéØ TARGET:** Achieve >95% test accuracy on MNIST dataset  \n",
        "**‚úÖ ACTUAL:** **97.56% test accuracy in just ONE epoch!**\n",
        "\n",
        "---\n",
        "\n",
        "### üìä **Performance Metrics**\n",
        "\n",
        "| Metric | Target | Achieved |\n",
        "|--------|---------|-----------|\n",
        "| **Test Accuracy** | >95% | **97.56%** |\n",
        "| **Model Parameters** | <25,000 | **24,418** |\n",
        "| **Training Efficiency** | Multiple epochs expected | **1 epoch only!** |\n",
        "| **Parameter Efficiency** | Good | **97.6% of limit used** |\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ofI8BKmQgx-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "era_v4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
