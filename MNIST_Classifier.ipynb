{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWMW6Y3fDQPh"
      },
      "source": [
        "# MNIST Handwritten Digit Classification\n",
        "\n",
        "## Overview\n",
        "This notebook implements a Convolutional Neural Network (CNN) for classifying handwritten digits from the MNIST dataset. The MNIST dataset contains 60,000 training images and 10,000 test images of handwritten digits (0-9), each 28x28 pixels in grayscale.\n",
        "\n",
        "## Project Goals\n",
        "- Build a lightweight CNN model with fewer than 25,000 parameters\n",
        "- Achieve high accuracy (>95%) on the MNIST test set\n",
        "- Implement proper data augmentation and regularization techniques\n",
        "- Visualize training progress and model performance\n",
        "\n",
        "## Key Features\n",
        "- **4-Block CNN Architecture**: Efficient convolutional blocks with transition layers\n",
        "- **Data Augmentation**: Random rotations, affine transforms, and color jittering\n",
        "- **Regularization**: Dropout layers and batch normalization techniques\n",
        "- **Global Average Pooling**: Reduces parameters compared to fully connected layers\n",
        "\n",
        "## Model Architecture Overview\n",
        "The model uses a 4-block CNN design:\n",
        "1. **Block 1**: Feature extraction (1‚Üí8‚Üí16‚Üí32 channels)\n",
        "2. **Block 2**: Pattern recognition (32‚Üí16‚Üí32‚Üí8 channels)\n",
        "3. **Block 3**: Higher-level features (8‚Üí16‚Üí16 channels)\n",
        "4. **Block 4**: Final feature refinement (16‚Üí32 channels)\n",
        "5. **GAP + FC**: Global average pooling + final classification layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KKZXp0FDoeJ"
      },
      "source": [
        "## 1. Import Required Libraries\n",
        "\n",
        "We'll import all the necessary libraries for building and training our CNN model:\n",
        "- **PyTorch**: Core deep learning framework\n",
        "- **torchvision**: For datasets and image transforms\n",
        "- **matplotlib**: For visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dPLHDfvR710P"
      },
      "outputs": [],
      "source": [
        "# Import core PyTorch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Import vision libraries for datasets and transforms\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Import additional libraries for visualization and utilities\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1. Reproducibility Setup\n",
        "\n",
        "For consistent and reproducible results across different runs and devices, we'll set seeds for all random number generators used in the pipeline:\n",
        "\n",
        "- **Python Random**: Built-in random module\n",
        "- **NumPy**: Scientific computing random numbers  \n",
        "- **PyTorch CPU**: PyTorch's CPU random number generator\n",
        "- **PyTorch CUDA**: NVIDIA GPU random number generator\n",
        "- **PyTorch MPS**: Apple Silicon GPU random number generator\n",
        "\n",
        "This ensures that data augmentation, model initialization, and training will produce identical results each time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üé≤ Setting random seed to 42 for reproducibility\n",
            "  ‚úÖ MPS (Apple Silicon) seed set\n",
            "  ‚úÖ All random number generators seeded\n",
            "  üìã Note: Results should now be reproducible across runs\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"\n",
        "    Set seeds for all random number generators to ensure reproducible results.\n",
        "    \n",
        "    Args:\n",
        "        seed (int): Random seed value (default: 42)\n",
        "    \"\"\"\n",
        "    print(f\"üé≤ Setting random seed to {seed} for reproducibility\")\n",
        "    \n",
        "    # Set Python's built-in random seed\n",
        "    random.seed(seed)\n",
        "    \n",
        "    # Set NumPy random seed\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Set PyTorch random seed for CPU\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    # Set PyTorch random seed for CUDA (if available)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
        "        # Ensure deterministic operations on GPU\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        print(\"  ‚úÖ CUDA seeds set with deterministic operations enabled\")\n",
        "    \n",
        "    # Set PyTorch random seed for MPS (if available)\n",
        "    if torch.backends.mps.is_available():\n",
        "        torch.mps.manual_seed(seed)\n",
        "        print(\"  ‚úÖ MPS (Apple Silicon) seed set\")\n",
        "    \n",
        "    # Set environment variable for Python hash seed (for complete reproducibility)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    \n",
        "    print(\"  ‚úÖ All random number generators seeded\")\n",
        "    print(\"  üìã Note: Results should now be reproducible across runs\")\n",
        "\n",
        "# Set the global seed\n",
        "SEED = 42\n",
        "set_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cR1-0DfEIAa"
      },
      "source": [
        "## 2. Device Setup and GPU Detection\n",
        "\n",
        "We'll check for available compute devices in order of preference:\n",
        "1. **CUDA** (NVIDIA GPUs) - Best performance for deep learning\n",
        "2. **MPS** (Apple Silicon Metal) - Optimized for Mac M1/M2/M3 chips\n",
        "3. **CPU** - Fallback option for compatibility\n",
        "\n",
        "This ensures optimal performance across different hardware configurations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvaMA6XHEM5O",
        "outputId": "83555802-c1c7-4666-c579-696732a36e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Using Apple Silicon GPU (Metal Performance Shaders)\n",
            "Device selected: mps\n"
          ]
        }
      ],
      "source": [
        "# Check for available compute devices\n",
        "def get_device():\n",
        "    \"\"\"\n",
        "    Determine the best available device for computation.\n",
        "    Priority: CUDA > MPS (Mac GPU) > CPU\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(f\"‚úÖ Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "        return device\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = torch.device(\"mps\")\n",
        "        print(\"‚úÖ Using Apple Silicon GPU (Metal Performance Shaders)\")\n",
        "        return device\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"‚ö†Ô∏è  Using CPU (consider using GPU for faster training)\")\n",
        "        return device\n",
        "\n",
        "# Set the device for training\n",
        "device = get_device()\n",
        "print(f\"Device selected: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIna1kDSEWJX"
      },
      "source": [
        "## 3. Data Preprocessing and Augmentation\n",
        "\n",
        "### Training Transforms\n",
        "We apply several augmentation techniques to increase dataset diversity and improve model generalization:\n",
        "- **RandomRotation(10¬∞)**: Slight rotations to handle natural writing variations\n",
        "- **RandomAffine**: Translation, scaling, and shearing transforms\n",
        "- **ColorJitter**: Brightness and contrast variations\n",
        "- **Normalization**: Using MNIST statistics (mean=0.1307, std=0.3081)\n",
        "\n",
        "### Test Transforms  \n",
        "For testing, we only apply normalization to ensure consistent preprocessing while maintaining reproducible results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4XjL7RB-8Cch"
      },
      "outputs": [],
      "source": [
        "# Define data transformations for training (with augmentation)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Define data transformations for testing (no augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mqx3pKlEjfv"
      },
      "source": [
        "## 4. Dataset Loading and Data Loaders\n",
        "\n",
        "We'll download and prepare the MNIST dataset with appropriate batch sizes for efficient training:\n",
        "- **Batch size**: 32 (balances memory usage and gradient stability)\n",
        "- **Shuffle**: Training data shuffled for better convergence\n",
        "- **Workers**: Multiple workers for parallel data loading\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-WzGcRY8E32",
        "outputId": "c279d761-9286-4abc-ecf2-7a427e56d205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 60,000\n",
            "Test samples: 10,000\n",
            "Number of classes: 10\n",
            "Image shape: torch.Size([1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST datasets with transforms\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "# Create data loaders for batch processing\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset):,}\")\n",
        "print(f\"Test samples: {len(test_dataset):,}\")\n",
        "print(f\"Number of classes: {len(train_dataset.classes)}\")\n",
        "print(f\"Image shape: {train_dataset[0][0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DhyLvxRE_xA"
      },
      "source": [
        "## 5. Data Visualization and Exploration\n",
        "\n",
        "Let's examine our training data to understand what we're working with:\n",
        "- **Sample Images**: Visualize a batch of training images\n",
        "- **Data Shape**: Confirm tensor dimensions (batch_size, channels, height, width)  \n",
        "- **Label Distribution**: Understand class balance in the dataset\n",
        "- **Augmentation Effects**: See how data transforms affect the images\n",
        "\n",
        "This visualization helps ensure our data loading pipeline is working correctly and gives us insight into the dataset characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "eCCKcWIp8Pww",
        "outputId": "bd1905c7-9a87-45f9-e8b0-864fc5d408f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Size torch.Size([32, 1, 28, 28])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 12 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_data, batch_label = next(iter(train_loader))\n",
        "print(f'Batch Size {batch_data.size()}')\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "for i in range(12):\n",
        "  plt.subplot(3,4,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(batch_data[i].squeeze(0), cmap='gray')\n",
        "  plt.title(batch_label[i].item())\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAiCL3yrFU-L"
      },
      "source": [
        "## 6. CNN Model Architecture\n",
        "\n",
        "Our **SmallMNISTNet4Block** is designed to be efficient yet powerful, staying under 25,000 parameters while achieving high accuracy.\n",
        "\n",
        "### Architecture Design Philosophy:\n",
        "- **Progressive Channel Reduction**: Each block processes features at different abstraction levels\n",
        "- **Transition Layers**: 1√ó1 convolutions reduce parameters and control information flow\n",
        "- **Strategic Dropout**: Applied at key points to prevent overfitting\n",
        "- **Global Average Pooling**: Replaces fully connected layers to reduce parameters\n",
        "- **Efficient Parameter Usage**: Every layer contributes meaningfully to the final result\n",
        "\n",
        "### Model Flow:\n",
        "```\n",
        "Input (1√ó28√ó28)\n",
        "‚Üì Block 1: Feature extraction (1‚Üí8‚Üí16‚Üí32‚Üí16 channels) + MaxPool + Dropout\n",
        "‚Üì Block 2: Pattern recognition (16‚Üí32‚Üí8 channels) + MaxPool + Dropout  \n",
        "‚Üì Block 3: High-level features (8‚Üí16 channels) + MaxPool + Dropout\n",
        "‚Üì Block 4: Final refinement (16‚Üí32 channels)\n",
        "‚Üì Global Average Pooling (32√ó1√ó1)\n",
        "‚Üì Linear Classification (32‚Üí10)\n",
        "‚Üì Output (10 classes)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PEwdHbHvZSwm"
      },
      "outputs": [],
      "source": [
        "class SmallMNISTNet4Block(nn.Module):\n",
        "    def __init__(self, dropout_prob=0.1):\n",
        "        super(SmallMNISTNet4Block, self).__init__()\n",
        "\n",
        "        # =============== BLOCK 1: Feature Extraction ===============\n",
        "        # Input: 1√ó28√ó28, RF=1\n",
        "        self.conv1_1 = nn.Conv2d(1, 8, 3, padding=1)    # ‚Üí 8√ó28√ó28\n",
        "        self.conv1_2 = nn.Conv2d(8, 16, 3, padding=1)   # ‚Üí 16√ó28√ó28\n",
        "        self.conv1_3 = nn.Conv2d(16, 32, 3, padding=1)  # ‚Üí 32√ó28√ó28\n",
        "        self.trans1 = nn.Conv2d(32, 16, 1)              # ‚Üí 16√ó28√ó28\n",
        "        # MaxPool2d(2): ‚Üí 16√ó14√ó14, RF=8\n",
        "        self.dropout1 = nn.Dropout2d(dropout_prob)       # ‚Üí 16√ó14√ó14\n",
        "\n",
        "        # =============== BLOCK 2: Pattern Recognition ===============\n",
        "        # Input: 16√ó14√ó14, RF=8\n",
        "        self.conv2_1 = nn.Conv2d(16, 16, 3, padding=1)  # ‚Üí 16√ó14√ó14\n",
        "        self.conv2_2 = nn.Conv2d(16, 32, 3, padding=1)  # ‚Üí 32√ó14√ó14\n",
        "        self.trans2 = nn.Conv2d(32, 8, 1)               # ‚Üí 8√ó14√ó14\n",
        "        # MaxPool2d(2): ‚Üí 8√ó7√ó7, RF=18\n",
        "        self.dropout2 = nn.Dropout2d(dropout_prob)       # ‚Üí 8√ó7√ó7\n",
        "\n",
        "        # =============== BLOCK 3: High-Level Features ===============\n",
        "        # Input: 8√ó7√ó7, RF=18\n",
        "        self.conv3_1 = nn.Conv2d(8, 16, 3, padding=1)   # ‚Üí 16√ó7√ó7\n",
        "        self.conv3_2 = nn.Conv2d(16, 16, 3, padding=1)  # ‚Üí 16√ó7√ó7\n",
        "        # MaxPool2d(2): ‚Üí 16√ó3√ó3, RF=38\n",
        "        self.dropout3 = nn.Dropout2d(dropout_prob)       # ‚Üí 16√ó3√ó3\n",
        "\n",
        "        # =============== BLOCK 4: Final Refinement ===============\n",
        "        # Input: 16√ó3√ó3, RF=38\n",
        "        self.conv4_1 = nn.Conv2d(16, 16, 3, padding=1)  # ‚Üí 16√ó3√ó3\n",
        "        self.conv4_2 = nn.Conv2d(16, 32, 3, padding=1)  # ‚Üí 32√ó3√ó3\n",
        "\n",
        "        # =============== GLOBAL POOLING & CLASSIFICATION ===============\n",
        "        # Input: 32√ó3√ó3, RF=70\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)               # ‚Üí 32√ó1√ó1\n",
        "        \n",
        "        # Input: 32 features, RF=70\n",
        "        self.fc = nn.Linear(32, 10)                      # ‚Üí 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # INPUT: x.shape = [batch, 1, 28, 28] | RF = 1\n",
        "        \n",
        "        # =============== BLOCK 1: Feature Extraction ===============\n",
        "        x = F.relu(self.conv1_1(x))      # [batch, 8, 28, 28]  \n",
        "        x = F.relu(self.conv1_2(x))      # [batch, 16, 28, 28] \n",
        "        x = F.relu(self.conv1_3(x))      # [batch, 32, 28, 28] \n",
        "        x = F.relu(self.trans1(x))       # [batch, 16, 28, 28] \n",
        "        x = F.max_pool2d(x, 2)           # [batch, 16, 14, 14] \n",
        "        x = self.dropout1(x)             # [batch, 16, 14, 14] \n",
        "\n",
        "        # =============== BLOCK 2: Pattern Recognition ===============  \n",
        "        x = F.relu(self.conv2_1(x))      # [batch, 16, 14, 14] \n",
        "        x = F.relu(self.conv2_2(x))      # [batch, 32, 14, 14] \n",
        "        x = F.relu(self.trans2(x))       # [batch, 8, 14, 14]  \n",
        "        x = F.max_pool2d(x, 2)           # [batch, 8, 7, 7]    \n",
        "        x = self.dropout2(x)             # [batch, 8, 7, 7]    \n",
        "\n",
        "        # =============== BLOCK 3: High-Level Features ===============\n",
        "        x = F.relu(self.conv3_1(x))      # [batch, 16, 7, 7]   \n",
        "        x = F.relu(self.conv3_2(x))      # [batch, 16, 7, 7]   \n",
        "        x = F.max_pool2d(x, 2)           # [batch, 16, 3, 3]   \n",
        "        x = self.dropout3(x)             # [batch, 16, 3, 3]   \n",
        "\n",
        "        # =============== BLOCK 4: Final Refinement ===============\n",
        "        x = F.relu(self.conv4_1(x))      # [batch, 16, 3, 3]   \n",
        "        x = F.relu(self.conv4_2(x))      # [batch, 32, 3, 3]   \n",
        "\n",
        "        # =============== GLOBAL POOLING & CLASSIFICATION ===============\n",
        "        x = self.gap(x)                  # [batch, 32, 1, 1]   \n",
        "        x = x.view(x.size(0), -1)        # [batch, 32]         \n",
        "        x = self.fc(x)                   # [batch, 10]         \n",
        "        \n",
        "        return F.log_softmax(x, dim=1)   # [batch, 10] (log probabilities)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz985g-NFm1c"
      },
      "source": [
        "## 7. Model Summary and Parameter Analysis\n",
        "\n",
        "Let's analyze our model architecture and verify it meets our parameter constraints:\n",
        "- **Total Parameters**: Should be < 25,000\n",
        "- **Memory Usage**: Efficient forward/backward pass\n",
        "- **Layer Distribution**: Balanced parameter allocation across blocks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJkyEL-PMOjE",
        "outputId": "da3a1ba9-0321-40b1-b2d1-ead957003d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "            Conv2d-2           [-1, 16, 28, 28]           1,168\n",
            "            Conv2d-3           [-1, 32, 28, 28]           4,640\n",
            "            Conv2d-4           [-1, 16, 28, 28]             528\n",
            "         Dropout2d-5           [-1, 16, 14, 14]               0\n",
            "            Conv2d-6           [-1, 16, 14, 14]           2,320\n",
            "            Conv2d-7           [-1, 32, 14, 14]           4,640\n",
            "            Conv2d-8            [-1, 8, 14, 14]             264\n",
            "         Dropout2d-9              [-1, 8, 7, 7]               0\n",
            "           Conv2d-10             [-1, 16, 7, 7]           1,168\n",
            "           Conv2d-11             [-1, 16, 7, 7]           2,320\n",
            "        Dropout2d-12             [-1, 16, 3, 3]               0\n",
            "           Conv2d-13             [-1, 16, 3, 3]           2,320\n",
            "           Conv2d-14             [-1, 32, 3, 3]           4,640\n",
            "AdaptiveAvgPool2d-15             [-1, 32, 1, 1]               0\n",
            "           Linear-16                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 24,418\n",
            "Trainable params: 24,418\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.56\n",
            "Params size (MB): 0.09\n",
            "Estimated Total Size (MB): 0.65\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = SmallMNISTNet4Block().to('cpu')\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Enhanced Training and Evaluation Functions\n",
        "\n",
        "We implement robust training and evaluation functions with comprehensive tracking and progress monitoring capabilities.\n",
        "\n",
        "### üöÄ Training Function Features (`train_epoch`)\n",
        "\n",
        "Our enhanced training function provides:\n",
        "\n",
        "- **Progress Visualization**: Real-time progress bars using `tqdm` showing current loss and accuracy\n",
        "- **Comprehensive Metrics**: Tracks both loss and accuracy throughout training\n",
        "- **Device Optimization**: Efficient GPU/MPS memory usage with `non_blocking=True`\n",
        "- **Memory Management**: Proper gradient zeroing and tensor operations\n",
        "- **Real-time Feedback**: Live updates of training metrics during each batch\n",
        "\n",
        "**Key Operations:**\n",
        "1. **Forward Pass**: Input ‚Üí Model ‚Üí Loss calculation\n",
        "2. **Backward Pass**: Gradient computation via backpropagation  \n",
        "3. **Optimization**: Parameter updates using Adam optimizer\n",
        "4. **Metrics Tracking**: Running totals for loss and accuracy\n",
        "5. **Progress Display**: Dynamic progress bar with live metrics\n",
        "\n",
        "### üìä Evaluation Function Features (`evaluate_model`)\n",
        "\n",
        "Our evaluation function ensures accurate model assessment:\n",
        "\n",
        "- **Evaluation Mode**: Sets model to `eval()` to disable dropout/batch norm training behavior\n",
        "- **No Gradient Computation**: Uses `torch.no_grad()` for memory efficiency\n",
        "- **Comprehensive Testing**: Processes entire test dataset with progress tracking\n",
        "- **Flexible Naming**: Supports different dataset names (Test/Validation)\n",
        "- **Consistent Metrics**: Same accuracy/loss calculations as training\n",
        "\n",
        "**Key Benefits:**\n",
        "- **Memory Efficient**: No gradient computation saves GPU memory\n",
        "- **Accurate Assessment**: Proper evaluation mode ensures realistic performance metrics\n",
        "- **Progress Tracking**: Visual feedback during evaluation process\n",
        "- **Consistent Interface**: Returns same format as training function\n",
        "\n",
        "### üîÑ Function Integration\n",
        "\n",
        "Both functions work together seamlessly:\n",
        "```python\n",
        "# Training phase\n",
        "train_loss, train_acc = train_epoch(model, device, train_loader, optimizer, criterion, epoch)\n",
        "\n",
        "# Evaluation phase  \n",
        "test_loss, test_acc = evaluate_model(model, device, test_loader, criterion, \"Test\")\n",
        "```\n",
        "\n",
        "This design enables:\n",
        "- **Easy Integration**: Drop-in replacements for basic train/test functions\n",
        "- **Comprehensive Logging**: Detailed metrics for analysis and debugging\n",
        "- **Professional Output**: Clean, informative progress displays\n",
        "- **Performance Monitoring**: Real-time feedback on training progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "J_ICqobTLtQU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_epoch(model, device, train_loader, optimizer, criterion, epoch=None):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch with comprehensive tracking and progress monitoring.\n",
        "    \n",
        "    Args:\n",
        "        model: The neural network model\n",
        "        device: Computing device (cuda/mps/cpu)\n",
        "        train_loader: DataLoader for training data\n",
        "        optimizer: Optimizer for parameter updates\n",
        "        criterion: Loss function\n",
        "        epoch: Current epoch number for display\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy_percentage)\n",
        "    \"\"\"\n",
        "    model.train()  # Set model to training mode\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    \n",
        "    # Create progress bar for training batches\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch} Training' if epoch else 'Training', \n",
        "                       leave=False, dynamic_ncols=True)\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
        "        # Move data to the appropriate device\n",
        "        data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
        "        \n",
        "        # Zero gradients from previous iteration\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update metrics\n",
        "        batch_loss = loss.item()\n",
        "        total_loss += batch_loss * data.size(0)\n",
        "        \n",
        "        # Calculate predictions and correct count\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct_predictions += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total_samples += data.size(0)\n",
        "        \n",
        "        # Update progress bar with current metrics\n",
        "        current_accuracy = 100. * correct_predictions / total_samples\n",
        "        progress_bar.set_postfix({\n",
        "            'Loss': f'{batch_loss:.4f}',\n",
        "            'Acc': f'{current_accuracy:.2f}%'\n",
        "        })\n",
        "    \n",
        "    # Calculate final epoch metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = 100. * correct_predictions / total_samples\n",
        "    \n",
        "    print(f'  Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.2f}%')\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def evaluate_model(model, device, test_loader, criterion, dataset_name=\"Test\"):\n",
        "    \"\"\"\n",
        "    Evaluate the model on test/validation data with comprehensive metrics.\n",
        "    \n",
        "    Args:\n",
        "        model: The neural network model\n",
        "        device: Computing device (cuda/mps/cpu)\n",
        "        test_loader: DataLoader for test data\n",
        "        criterion: Loss function\n",
        "        dataset_name: Name for display purposes (\"Test\" or \"Validation\")\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (average_loss, accuracy_percentage)\n",
        "    \"\"\"\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    \n",
        "    # Create progress bar for evaluation batches\n",
        "    progress_bar = tqdm(test_loader, desc=f'{dataset_name} Evaluation', \n",
        "                       leave=False, dynamic_ncols=True)\n",
        "    \n",
        "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
        "        for data, target in progress_bar:\n",
        "            # Move data to the appropriate device\n",
        "            data, target = data.to(device, non_blocking=True), target.to(device, non_blocking=True)\n",
        "            \n",
        "            # Forward pass\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            # Update metrics\n",
        "            total_loss += loss.item() * data.size(0)\n",
        "            \n",
        "            # Calculate predictions and correct count\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct_predictions += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total_samples += data.size(0)\n",
        "            \n",
        "            # Update progress bar\n",
        "            current_accuracy = 100. * correct_predictions / total_samples\n",
        "            progress_bar.set_postfix({'Acc': f'{current_accuracy:.2f}%'})\n",
        "    \n",
        "    # Calculate final metrics\n",
        "    avg_loss = total_loss / total_samples\n",
        "    accuracy = 100. * correct_predictions / total_samples\n",
        "    \n",
        "    print(f'  {dataset_name} Loss: {avg_loss:.4f}, {dataset_name} Accuracy: {accuracy:.2f}%')\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6NPG4kw1Vg6-"
      },
      "outputs": [],
      "source": [
        "model = SmallMNISTNet4Block().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                      \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.7935, Train Accuracy: 72.36%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                               "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Test Loss: 0.1270, Test Accuracy: 95.95%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.12698739351555705, 95.95)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_epoch(model, device, train_loader, optimizer, criterion)\n",
        "evaluate_model(model, device, test_loader, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "### üèÜ **Summary**\n",
        "\n",
        "**üéØ TARGET:** Achieve >95% test accuracy on MNIST dataset  \n",
        "**‚úÖ ACTUAL:** **95.77% test accuracy in just ONE epoch!**\n",
        "\n",
        "---\n",
        "\n",
        "### üìä **Performance Metrics**\n",
        "\n",
        "| Metric | Target | Achieved |\n",
        "|--------|---------|-----------|\n",
        "| **Test Accuracy** | >95% | **95.95%** |\n",
        "| **Model Parameters** | <25,000 | **24,418** |\n",
        "| **Training Efficiency** | Multiple epochs expected | **1 epoch only!** |\n",
        "| **Parameter Efficiency** | Good | **97.6% of limit used** |\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ofI8BKmQgx-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "era_v4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
